{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d6133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kayak\\AppData\\Local\\Temp\\ipykernel_8464\\1973093605.py:231: DtypeWarning: Columns (302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_EAM = pd.read_csv(ruta_archivo, sep=CSV_SEPARATOR)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Importado y nombres estandarizados: EAM_ANONIMIZADA_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kayak\\AppData\\Local\\Temp\\ipykernel_8464\\1973093605.py:231: DtypeWarning: Columns (302) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_EAM = pd.read_csv(ruta_archivo, sep=CSV_SEPARATOR)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Importado y nombres estandarizados: EAM_ANONIMIZADA_2019.csv\n",
      "✅ Importado y nombres estandarizados: EAM_ANONIMIZADA_2020.xlsx\n",
      "✅ Importado y nombres estandarizados: EAM_ANONIMIZADA_2021.xlsx\n",
      "✅ Importado y nombres estandarizados: EAM_ANONIMIZADA_2022.xlsx\n",
      "✅ Importado y nombres estandarizados: EAM_ANONIMIZADA_2023.xlsx\n",
      "\n",
      "--- PROCESO TERMINADO ---\n",
      "DataFrames consolidados para los años: 2018 a 2023\n",
      "Total de registros consolidados (Filas): 138\n",
      "\n",
      "Primeras filas del DataFrame Consolidado (EAM):\n",
      "   DEPARTAMENTO   AÑO  Impuesto de Renta para la Equidad  \\\n",
      "0             5  2018                                0.0   \n",
      "1             8  2018                                0.0   \n",
      "2            11  2018                                0.0   \n",
      "3            13  2018                                0.0   \n",
      "4            15  2018                                0.0   \n",
      "5            17  2018                                0.0   \n",
      "6            19  2018                                0.0   \n",
      "7            20  2018                                0.0   \n",
      "8            23  2018                                0.0   \n",
      "9            25  2018                                0.0   \n",
      "\n",
      "   Impuesto del 4 x 1 000  Impuesto de Industria y Comercio  \\\n",
      "0             161143552.0                       209177913.0   \n",
      "1              45410108.0                        61443599.0   \n",
      "2             147122946.0                       288579378.0   \n",
      "3              42862190.0                       108368051.0   \n",
      "4               8914892.0                        14440007.0   \n",
      "5              55487653.0                        25164452.0   \n",
      "6              18837358.0                        42318050.0   \n",
      "7               2687462.0                         3121238.0   \n",
      "8               7014235.0                         2271281.0   \n",
      "9              75827291.0                       184631269.0   \n",
      "\n",
      "   Impuesto Predial y sobre Vehículos  \n",
      "0                          63446694.0  \n",
      "1                          17974027.0  \n",
      "2                          91316705.0  \n",
      "3                          34589274.0  \n",
      "4                           1554821.0  \n",
      "5                           5740726.0  \n",
      "6                           3268752.0  \n",
      "7                           2401405.0  \n",
      "8                           2563536.0  \n",
      "9                          21415391.0  \n",
      "✅ Columnas eliminadas con éxito: ['PRODUCTOS PLÁSTICOS 10/', 'BEBIDAS ULTRA PROCESADAS 11/', 'PRODUCTOS COMESTIBLES 12/', 'IMPUESTO ESPECIAL PARA EL CATATUMBO14/']\n",
      "\n",
      "--- FUSIÓN Y FILTRADO COMPLETADA ---\n",
      "El DataFrame df_EAM_impuestos final contiene los datos sin los 4 impuestos excluidos.\n",
      "   dpto   AÑO  Impuesto de Renta para la Equidad  Impuesto del 4 x 1 000  \\\n",
      "0     5  2018                                0.0             161143552.0   \n",
      "1     5  2019                                0.0             151994122.0   \n",
      "2     5  2020                           482650.0             156406257.0   \n",
      "3     5  2021                                0.0             193311710.0   \n",
      "4     5  2022                                0.0             241099797.0   \n",
      "\n",
      "   Impuesto de Industria y Comercio  Impuesto Predial y sobre Vehículos  \\\n",
      "0                       209177913.0                          63446694.0   \n",
      "1                       220700716.0                          71751426.0   \n",
      "2                       215804911.0                          60555115.0   \n",
      "3                       298198694.0                          58628406.0   \n",
      "4                       452491859.0                          74554417.0   \n",
      "\n",
      "   RENTA CUOTAS  IVA DECLARACIONES 2/  RETENCIONES 3/   EXTERNOS 4/  ...  \\\n",
      "0  2.190594e+09          5.272050e+09    8.485847e+09  8.726740e+08  ...   \n",
      "1  2.048459e+09          5.801992e+09    9.498548e+09  1.001763e+09  ...   \n",
      "2  2.073955e+09          5.738992e+09    9.483689e+09  9.649680e+08  ...   \n",
      "3  2.429716e+09          5.297967e+09    8.542911e+09  1.289102e+09  ...   \n",
      "4  1.659076e+09          3.893575e+09    4.584569e+09  1.707082e+09  ...   \n",
      "\n",
      "   GASOLINA Y ACPM  CREE RETENCIONES  CREE DECLARACIONES  AL CARBONO  \\\n",
      "0              0.0       1487000.000         6755000.000      5000.0   \n",
      "1           2000.0        538000.000         6784000.000      4000.0   \n",
      "2          45000.0        847000.000         3288000.000      3000.0   \n",
      "3              0.0        259146.646         1287092.445      2690.0   \n",
      "4            185.0        121786.000          508542.204         0.0   \n",
      "\n",
      "     SIMPLE 7/  NORMALIZACION 8/  CONSUMO BIENES 9/  IVA_EXTERIOR  \\\n",
      "0          0.0      0.000000e+00                0.0           0.0   \n",
      "1   13171000.0      1.905470e+08         13774000.0           0.0   \n",
      "2   54096000.0      8.869300e+07           627000.0       11000.0   \n",
      "3  108253872.0      3.326664e+07           798329.0         502.0   \n",
      "4  219450239.0      3.918507e+07          1663805.0       10978.0   \n",
      "\n",
      "   POR CLASIFICAR 13/      TOTAL **  \n",
      "0        5.895000e+06  2.014754e+10  \n",
      "1        1.140000e+07  2.247288e+10  \n",
      "2        1.361600e+07  2.214877e+10  \n",
      "3        1.907820e+07  2.077498e+10  \n",
      "4        1.676054e+07  1.246675e+10  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "import openpyxl as op\n",
    "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# PREPARACIÓN E IMPORTACIÓN DE DATOS DIAN (RECAUDO BRUTO)\n",
    "\n",
    "# Ruta base de la carpeta \"datasets\" (AJUSTAR ESTA RUTA SI ES NECESARIO)\n",
    "ruta_datasets = r\"C:\\Users\\Kayak\\OneDrive\\Escritorio\\U\\2025-2\\IA_aplicada\\proyecto\\datasets\"\n",
    "# Nombre del primer archivo que es tipo xlsx\n",
    "Recaudo_Bruto = \"Estadisticas-de-Recaudo-bruto-por-seccionales-y-tipo-de-impuesto-2005-2025.xlsx\"\n",
    "\n",
    "# creamos ruta para importar el primer archivo\n",
    "ruta_Recaudo_Bruto = os.path.join(ruta_datasets, Recaudo_Bruto)\n",
    "\n",
    "# carga del archivo usando la ruta, saltándonos las primeras 5 filas y las últimas 10\n",
    "df_impuestos = pd.read_excel(ruta_Recaudo_Bruto,  skiprows=5,skipfooter=10)\n",
    "# al ver el dataframe, notamos que la fila 1 y 2 están fusionadas por lo que debemos eliminar una\n",
    "df_impuestos=df_impuestos.drop(index=0)\n",
    "\n",
    "# de otro lado la columna AÑO debe ser rellenada (forward fill)\n",
    "df_impuestos['AÑO'] = df_impuestos['AÑO'].ffill()\n",
    "\n",
    "# Ahora bien, vamos a manejar datos solamente de 2018 a 2023, por lo que filtramos el dataframe\n",
    "df_impuestos['AÑO'] = pd.to_numeric(df_impuestos['AÑO'], errors='coerce')  # Convertir a numérico\n",
    "df_impuestos = df_impuestos[(df_impuestos['AÑO'] >= 2018) & (df_impuestos['AÑO'] <= 2023)]\n",
    "df_impuestos['AÑO'] = df_impuestos['AÑO'].astype(int)\n",
    "df_impuestos.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Normalizar los nombres en la columna DIRECCIÓN_SECCIONAL\n",
    "df_impuestos[\"DIRECCIÓN SECCIONAL\"] = (\n",
    "    df_impuestos[\"DIRECCIÓN SECCIONAL\"]\n",
    "    .str.strip()  # elimina espacios antes/después\n",
    "    .str.upper() ) # pasa todo a mayúsculas\n",
    "\n",
    "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# CONVERSIÓN DE UNIDADES (Millones a Miles de $COP)\n",
    "\n",
    "\n",
    "# hay columnas tipo texto asi que vamos a ignorarlas para trabajar sin errores en una conversión de formato.\n",
    "columnas_excluidas = ['AÑO', 'DIRECCIÓN SECCIONAL']\n",
    "columnas_a_convertir = df_impuestos.columns.drop(columnas_excluidas)\n",
    "\n",
    "# conversión solo a esas columnas. Reemplazamos no-números con NaN y luego multiplicamos.\n",
    "df_impuestos[columnas_a_convertir] = df_impuestos[columnas_a_convertir].apply(pd.to_numeric, errors='coerce')\n",
    "# Multiplicación para pasar de Millones a Miles (Millones * 1000)\n",
    "df_impuestos[columnas_a_convertir] = df_impuestos[columnas_a_convertir] * 1000\n",
    "# convertimos los valores NaN a 0\n",
    "df_impuestos = df_impuestos.fillna(0)\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# MAPPING DE SECCIONALES A DEPARTAMENTO Y CÓDIGO (DIAN\n",
    "\n",
    "# Diccionario ciudad -> departamento (ajustado a mayúsculas)\n",
    "ciudades_departamentos = {\n",
    "    \"ADUANAS BARRANQUILLA\": \"ATLÁNTICO\",\n",
    "    \"ADUANAS BOGOTA\": \"CUNDINAMARCA\",\n",
    "    \"ADUANAS CALI\": \"VALLE DEL CAUCA\",\n",
    "    \"ADUANAS CARTAGENA\": \"BOLÍVAR\",\n",
    "    \"ADUANAS DE CUCUTA\": \"NORTE DE SANTANDER\",\n",
    "    \"ADUANAS DE MEDELLIN\": \"ANTIOQUIA\",\n",
    "    \"IMPUESTOS BOGOTA\": \"CUNDINAMARCA\",\n",
    "    \"GRANDES CONTRIBUYENTES BOGOTA\": \"BOGOTÁ, D.C.\",\n",
    "    \"OPERERATIVA DE GRANDES CONTRIBUYENTES\": \"BOGOTÁ, D.C.\",\n",
    "    \"OPERATIVA GRANDES CONTRIBUYENTES\": \"BOGOTÁ, D.C.\",\n",
    "\n",
    "    \"ARAUCA\": \"ARAUCA\",\n",
    "    \"ARMENIA\": \"QUINDÍO\",\n",
    "    \"BARRANCABERMEJA\": \"SANTANDER\",\n",
    "    \"BARRANQUILLA\": \"ATLÁNTICO\",\n",
    "    \"BUCARAMANGA\": \"SANTANDER\",\n",
    "    \"BUENAVENTURA\": \"VALLE DEL CAUCA\",\n",
    "    \"CALI\": \"VALLE DEL CAUCA\",\n",
    "    \"CARTAGENA\": \"BOLÍVAR\",\n",
    "    \"CUCUTA\": \"NORTE DE SANTANDER\",\n",
    "    \"FLORENCIA\": \"CAQUETÁ\",\n",
    "    \"GIRARDOT\": \"CUNDINAMARCA\",\n",
    "    \"IBAGUE\": \"TOLIMA\",\n",
    "    \"INIRIDA\": \"GUAINÍA\",\n",
    "    \"IPIALES\": \"NARIÑO\",\n",
    "    \"LETICIA\": \"AMAZONAS\",\n",
    "    \"MAICAO\": \"LA GUAJIRA\",\n",
    "    \"MANIZALES\": \"CALDAS\",\n",
    "    \"MEDELLIN\": \"ANTIOQUIA\",\n",
    "    \"MITU\": \"VAUPÉS\",\n",
    "    \"MONTERIA\": \"CÓRDOBA\",\n",
    "    \"NEIVA\": \"HUILA\",\n",
    "    \"PALMIRA\": \"VALLE DEL CAUCA\",\n",
    "    \"PASTO\": \"NARIÑO\",\n",
    "    \"PEREIRA\": \"RISARALDA\",\n",
    "    \"POPAYAN\": \"CAUCA\",\n",
    "    \"PUERTO ASIS\": \"PUTUMAYO\",\n",
    "    \"PUERTO CARREÑO\": \"VICHADA\",\n",
    "    \"QUIBDO\": \"CHOCÓ\",\n",
    "    \"RIOHACHA\": \"LA GUAJIRA\",\n",
    "    \"SAN ANDRES\": \"ARCHIPIÉLAGO DE SAN ANDRÉS, PROVIDENCIA Y SANTA CATALINA\",\n",
    "    \"SAN JOSE DEL GUAVIARE\": \"GUAVIARE\",\n",
    "    \"SANTA MARTA\": \"MAGDALENA\",\n",
    "    \"SINCELEJO\": \"SUCRE\",\n",
    "    \"SOGAMOSO\": \"BOYACÁ\",\n",
    "    \"TULUA\": \"VALLE DEL CAUCA\",\n",
    "    \"TUNJA\": \"BOYACÁ\",\n",
    "    \"URABA\": \"ANTIOQUIA\",\n",
    "    \"VALLEDUPAR\": \"CESAR\",\n",
    "    \"VILLAVICENCIO\": \"META\",\n",
    "    \"YOPAL\": \"CASANARE\"\n",
    "}\n",
    "\n",
    "# Diccionario departamento -> código\n",
    "departamento_codigos = {\n",
    "    \"ANTIOQUIA\": 5,\n",
    "    \"ATLÁNTICO\": 8,\n",
    "    \"BOGOTÁ, D.C.\": 11,\n",
    "    \"BOLÍVAR\": 13,\n",
    "    \"BOYACÁ\": 15,\n",
    "    \"CALDAS\": 17,\n",
    "    \"CAQUETÁ\": 18,\n",
    "    \"CAUCA\": 19,\n",
    "    \"CESAR\": 20,\n",
    "    \"CÓRDOBA\": 23,\n",
    "    \"CUNDINAMARCA\": 25,\n",
    "    \"CHOCÓ\": 27,\n",
    "    \"HUILA\": 41,\n",
    "    \"LA GUAJIRA\": 44,\n",
    "    \"MAGDALENA\": 47,\n",
    "    \"META\": 50,\n",
    "    \"NARIÑO\": 52,\n",
    "    \"NORTE DE SANTANDER\": 54,\n",
    "    \"QUINDÍO\": 63,\n",
    "    \"RISARALDA\": 66,\n",
    "    \"SANTANDER\": 68,\n",
    "    \"SUCRE\": 70,\n",
    "    \"TOLIMA\": 73,\n",
    "    \"VALLE DEL CAUCA\": 76,\n",
    "    \"ARAUCA\": 81,\n",
    "    \"CASANARE\": 85,\n",
    "    \"PUTUMAYO\": 86,\n",
    "    \"ARCHIPIÉLAGO DE SAN ANDRÉS, PROVIDENCIA Y SANTA CATALINA\": 88,\n",
    "    \"AMAZONAS\": 91,\n",
    "    \"GUAINÍA\": 94,\n",
    "    \"GUAVIARE\": 95,\n",
    "    \"VAUPÉS\": 97,\n",
    "    \"VICHADA\": 99\n",
    "}\n",
    "\n",
    "# eliminación de filas de totales por año\n",
    "df_impuestos_arreglado = df_impuestos[~df_impuestos[\"DIRECCIÓN SECCIONAL\"].str.contains(\"TOTAL AÑO\", case=False, na=False)].copy()\n",
    "# Asignación de departamento\n",
    "df_impuestos_arreglado[\"departamento\"] = df_impuestos_arreglado[\"DIRECCIÓN SECCIONAL\"].map(ciudades_departamentos)\n",
    "\n",
    "# Asignación de código de departamento\n",
    "df_impuestos_arreglado[\"dpto\"] = df_impuestos_arreglado[\"departamento\"].map(departamento_codigos)\n",
    "df_impuestos_arreglado['dpto'] = df_impuestos_arreglado['dpto'].apply(pd.to_numeric, errors='coerce')\n",
    "df_impuestos_arreglado = df_impuestos_arreglado.dropna(subset=[\"dpto\"])\n",
    "df_impuestos_arreglado[\"dpto\"] = df_impuestos_arreglado[\"dpto\"].astype(int)\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# CONSOLIDACIÓN DIAN POR DPTO Y AÑO \n",
    "\n",
    "# Agrupar por 'dpto' y 'AÑO' y sumar los valores de recaudo para consolidar\n",
    "# todas las seccionales (Aduanas, Impuestos, Grandes Contribuyentes) en un\n",
    "# único total por cada departamento y año.\n",
    "df_DIAN_consolidado = df_impuestos_arreglado.groupby(['dpto', 'AÑO']).sum(numeric_only=True).reset_index()\n",
    "\n",
    "# Función para limpiar los nombres de columnas (eliminar espacios no deseados y \\xa0)\n",
    "def clean_col_name(col):\n",
    "    col = col.replace('\\xa0', ' ') # Reemplazar espacio no-breaking con espacio normal\n",
    "    col = col.strip()             # Eliminar espacios iniciales/finales (incluyendo \\n)\n",
    "    col = ' '.join(col.split())   # Colapsar múltiples espacios internos a uno solo\n",
    "    return col\n",
    "\n",
    "# Aplicar la limpieza a los nombres de las columnas del DataFrame de la DIAN\n",
    "df_DIAN_consolidado.columns = [clean_col_name(col) for col in df_DIAN_consolidado.columns]\n",
    "\n",
    "# Opcional: limpiar columnas que no son de impuestos después de la suma\n",
    "columnas_a_mantener_dian = ['dpto', 'AÑO'] + [col for col in df_DIAN_consolidado.columns if col not in ['dpto', 'AÑO', 'DIRECCIÓN SECCIONAL', 'departamento']]\n",
    "df_DIAN_consolidado = df_DIAN_consolidado[columnas_a_mantener_dian]\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# IMPORTACIÓN Y PROCESAMIENTO DE DATOS EAM (DANE)\n",
    "\n",
    "#dado que son varios datasets, vamos a hacer un bucle para procesarlos todos de forma\n",
    "#eficiente. Algo importante es que en la agrupación de la base de datos no queremos\n",
    "# tomar en cuenta las columnas que no son de impuestos, por lo que haremos un renombramiento\n",
    "# y una selección previa de las columnas que nos interesan, tampoco vamos a eliminarlas pues\n",
    "# las necesitaremos para hacer merge de las bases más adelante.\n",
    "\n",
    "# indicación de la ruta de los datasets y el separador de los archivos csv\n",
    "ruta_datasets = r'C:\\Users\\Kayak\\OneDrive\\Escritorio\\U\\2025-2\\IA_aplicada\\proyecto\\datasets'\n",
    "CSV_SEPARATOR = ';'\n",
    "\n",
    "# Diccionario de configuración de archivos y formato exacto por año\n",
    "archivos = {\n",
    "    2018: {'nombre': 'EAM_ANONIMIZADA_2018.csv', 'formato': 'csv'},\n",
    "    2019: {'nombre': 'EAM_ANONIMIZADA_2019.csv', 'formato': 'csv'},\n",
    "    2020: {'nombre': 'EAM_ANONIMIZADA_2020.xlsx', 'formato': 'xlsx'},\n",
    "    2021: {'nombre': 'EAM_ANONIMIZADA_2021.xlsx', 'formato': 'xlsx'},\n",
    "    2022: {'nombre': 'EAM_ANONIMIZADA_2022.xlsx', 'formato': 'xlsx'},\n",
    "    2023: {'nombre': 'EAM_ANONIMIZADA_2023.xlsx', 'formato': 'xlsx'}\n",
    "}\n",
    "\n",
    "# Diccionario de decodificación y selección de columnas\n",
    "columnas_renombre = {\n",
    "    'dpto': 'DEPARTAMENTO',\n",
    "    'periodo': 'AÑO',\n",
    "    'C3R20C3': 'Impuesto de Renta para la Equidad',\n",
    "    'c3r25c3': 'Impuesto del 4 x 1 000',\n",
    "    'c3r37c3': 'Impuesto de Industria y Comercio',\n",
    "    'c3r38c3': 'Impuesto Predial y sobre Vehículos'\n",
    "}\n",
    "columnas_seleccion = list(columnas_renombre.keys()) # Las columnas originales que buscamos\n",
    "columnas_impuestos = list(columnas_renombre.values())[2:] # Solo los nombres de los impuestos finales\n",
    "\n",
    "# Lista para almacenar los DataFrames procesados anualmente\n",
    "list_df_anuales = []\n",
    "\n",
    "# Bucle de Procesamiento\n",
    "for año, dataset in archivos.items():\n",
    "    nombre_archivo = dataset['nombre']\n",
    "    formato_archivo = dataset['formato']\n",
    "    ruta_archivo = os.path.join(ruta_datasets, nombre_archivo)\n",
    "    df_EAM = None\n",
    "\n",
    "    # Importación Condicional\n",
    "    try:\n",
    "        if formato_archivo == 'xlsx':\n",
    "            df_EAM = pd.read_excel(ruta_archivo)\n",
    "        elif formato_archivo == 'csv':\n",
    "            df_EAM = pd.read_csv(ruta_archivo, sep=CSV_SEPARATOR)\n",
    "        else:\n",
    "            print(f\" Error: Formato '{formato_archivo}' no reconocido.\")\n",
    "            continue\n",
    "\n",
    "        # Estandarización de nombres: convierte los nombres de columnas a minúsculas\n",
    "        df_EAM.columns = df_EAM.columns.str.lower().str.strip()\n",
    "        print(f\"✅ Importado y nombres estandarizados: {nombre_archivo}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\" Error: Archivo NO encontrado en la ruta para el año {año}.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\" Error al leer el archivo {nombre_archivo}. Detalles: {e}\")\n",
    "        continue\n",
    "\n",
    "    #Selección y Renombramiento\n",
    "    columnas_a_seleccionar_limpias = [col.lower() for col in columnas_seleccion]\n",
    "\n",
    "    try:\n",
    "        # Aquí aplicamos la selección de columnas.\n",
    "        df_EAM_util = df_EAM[columnas_a_seleccionar_limpias].copy()\n",
    "    except KeyError as e:\n",
    "        print(f\" ERROR CRÍTICO en el año {año}: Columnas no encontradas. Faltan: {e}. Revisar el archivo.\")\n",
    "        print(f\"Columnas disponibles: {df_EAM.columns.tolist()}\")\n",
    "        continue\n",
    "\n",
    "    # Renombramos usando los nombres limpios como clave\n",
    "    columnas_renombre_limpio = {k.lower(): v for k, v in columnas_renombre.items()}\n",
    "    df_EAM_util = df_EAM_util.rename(columns=columnas_renombre_limpio)\n",
    "\n",
    "\n",
    "    #Convertimos  los datos a numero (Necesario para sumar después de leer CSV/TXT)\n",
    "    for col in columnas_impuestos:\n",
    "        df_EAM_util[col] = pd.to_numeric(df_EAM_util[col], errors='coerce')\n",
    "\n",
    "    # Agrupación y Suma por Departamento\n",
    "    df_EAM_sumado_por_dpto = df_EAM_util.groupby('DEPARTAMENTO').sum(numeric_only=True).reset_index()\n",
    "\n",
    "    # hay una columna que se llama año pero en la base de la DIAN se llama AÑO por\n",
    "    # lo que vamos a crear una nueva columna llamada AÑO y le asignamos el valor del año actual\n",
    "    df_EAM_sumado_por_dpto['AÑO'] = año\n",
    "\n",
    "    #Almacenamiento para concatenación\n",
    "    list_df_anuales.append(df_EAM_sumado_por_dpto)\n",
    "\n",
    "\n",
    "# --- Consolidación Final EAM ---\n",
    "# Concatenación vertical (apilamiento) de todos los resúmenes anuales.\n",
    "df_EAM_consolidado = pd.concat(list_df_anuales, ignore_index=True)\n",
    "df_EAM_consolidado.rename(columns={'DEPARTAMENTO': 'dpto'}, inplace=True)\n",
    "print(\"\\n--- PROCESO TERMINADO ---\")\n",
    "print(\"\\nPrimeras filas de la EAM):\")\n",
    "print(df_EAM_consolidado.head(10))\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# CRUCE FINAL DE DATOS \n",
    "\n",
    "# Usamos df_DIAN_consolidado (el agrupado) y la doble clave ['dpto', 'AÑO']\n",
    "df_EAM_impuestos = pd.merge(df_EAM_consolidado, df_DIAN_consolidado, on=['dpto', 'AÑO'], how='outer')\n",
    "df_EAM_impuestos = df_EAM_impuestos.fillna(0)\n",
    "\n",
    "# Eliminación de columnas vacías.\n",
    "# con clean_col_name() vamos a limpiar los nombres de las columnas que queremos eliminar.\n",
    "#luego las eliminamos del dataframe final.\n",
    "#manteniendo el resto de columnas de EAM y DIAN.\n",
    "\n",
    "columnas_a_eliminar_sucias = [\n",
    "    'PRODUCTOS PLÁSTICOS 10/', 'BEBIDAS ULTRA PROCESADAS 11/',\n",
    "    'PRODUCTOS COMESTIBLES 12/', 'IMPUESTO ESPECIAL PARA EL CATATUMBO14/']\n",
    "\n",
    "columnas_a_eliminar = [clean_col_name(col) for col in columnas_a_eliminar_sucias]\n",
    "df_EAM_impuestos = df_EAM_impuestos.drop(columns=columnas_a_eliminar, errors='raise')\n",
    "df_EAM_impuestos.to_excel(\"EAM final.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b70f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EAM_impuestos = df_EAM_impuestos.fillna(0)\n",
    "df_EAM_impuestos.to_excel(\"EAM final.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "import openpyxl as op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1808225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que muestre todas las columnas\n",
    "pd.options.display.max_columns = None\n",
    "# En los dataframes, mostrar los float con dos decimales\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf90ac",
   "metadata": {},
   "source": [
    "# IMPORTACIÓN DE DATOS\n",
    "\n",
    "## Fuentes de los datos:\n",
    "\n",
    ">la DIAN proporciona información en sus estadisticas sobre Recaudo Bruto por Seccionales y Tipo de Impuesto 2005 - 2025, estos datos están en millones de $COP \n",
    "\n",
    ">El DANE en su Encuesta Anual Manufacturera recolecta datos de las empresas con el fin de obtener información básica del sector fabril que permita el conocimiento de su estructura, evolución y desarrollo. Utilizaremos esta base de datos para darnos acceso a la información sobre las empresas del sector industrial en particular del pago de impuestos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82777a9",
   "metadata": {},
   "source": [
    "## Acceso a datos:\n",
    ">DIAN: https://www.dian.gov.co/dian/cifras/Paginas/EstadisticasRecaudo.aspx\n",
    "\n",
    ">DANE: portal micro datos: https://microdatos.dane.gov.co/index.php/catalog/central/about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd02e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el directorio actual \n",
    "directorio_inicial = os.getcwd()\n",
    "print(f\"Directorio inicial: {directorio_inicial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b340b6b",
   "metadata": {},
   "source": [
    "## Importación de dataset de la DIAN:\n",
    "El objetivo es obtener datos para el intervalo 2018-2023 que estén completos y limpios con una nueva columna llamada departamento que será la que usemos para unir los datos del dane con la DIAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bb7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#como queremos seguir en el directorio actual, pero los datos están cargados en otro folder, \n",
    "# vamos a generar una función que nos permita acceder a esa ruta donde estás los datasets y \n",
    "# ahorrar espacio el tiempo en el codigo, cosa que nos será util más adelante al importar \n",
    "# más datos, porque ya tendremos la ruta al folder definida.\n",
    "\n",
    "# Ruta base de la carpeta \"datasets\"\n",
    "ruta_datasets = r\"C:\\Users\\Kayak\\OneDrive\\Escritorio\\U\\2025-2\\IA_aplicada\\proyecto\\datasets\" \n",
    "# Nombre del primer archivo que es tipo xlsx\n",
    "Recaudo_Bruto = \"Estadisticas-de-Recaudo-bruto-por-seccionales-y-tipo-de-impuesto-2005-2025.xlsx\"\n",
    "\n",
    "#creamos ruta para importar el priemer archivo\n",
    "ruta_Recaudo_Bruto = os.path.join(ruta_datasets, Recaudo_Bruto)\n",
    "\n",
    "# carga del archivo usando la ruta, saltandonos las primeras 5 filas y las últimas 10 porque son titulos o aclaraciones \n",
    "df_impuestos = pd.read_excel(ruta_Recaudo_Bruto,  skiprows=5,skipfooter=10)\n",
    "#veamos que tipo de datos hay en cada columna y convirtamos a float los datos del recaudo que sean números.\n",
    "# al ver el dataframe, notamos que la fila 1 y 2 están fusionadas por lo que debemos eliminar una dado que no aporta nada al analisis.\n",
    "df_impuestos=df_impuestos.drop(index=0)\n",
    "\n",
    "#de otro lado la columna AÑO debe ser rellenada, porque tiene muchos valores NaN debido a tener celdas combinadas en la base de datos.\n",
    "# para ello usamos el método fillna con el parámetro method='ffill' (forward fill) que rellena los valores NaN con el último valor no nulo encontrado hacia adelante.\n",
    "df_impuestos['AÑO'] = df_impuestos['AÑO'].ffill()\n",
    "\n",
    "#Ahora bien, vamos a manejar datos solamente de 2018 a 2023, por lo que filtramos el dataframe para quedarnos solo con esos años.\n",
    "df_impuestos['AÑO'] = pd.to_numeric(df_impuestos['AÑO'], errors='coerce')  # Convertir a numérico, forzando errores a NaN\n",
    "df_impuestos = df_impuestos[(df_impuestos['AÑO'] >= 2018) & (df_impuestos['AÑO'] <= 2023)]\n",
    "df_impuestos['AÑO'] = df_impuestos['AÑO'].astype(int)\n",
    "df_impuestos.reset_index(inplace=True, drop=True) \n",
    "\n",
    "# Normalizar los nombres en la columna DIRECCIÓN_SECCIONAL\n",
    "df_impuestos[\"DIRECCIÓN SECCIONAL\"] = (\n",
    "    df_impuestos[\"DIRECCIÓN SECCIONAL\"]\n",
    "    .str.strip()  # elimina espacios antes/después\n",
    "    .str.upper() ) # pasa todo a mayúsculas\n",
    "\n",
    "# los datos de la DIAN están en millones $COP, los del Dane están en miles de $COP\n",
    "# por lo tanto, para que las unidades sean consistentes, convertiremos los datos de la DIAN a miles de $COP\n",
    "#hay columnas tipo texto asi que vamos a ignorarlas para trabajar sin errores en una conversión de formato.\n",
    "columnas_excluidas = ['AÑO', 'DIRECCIÓN SECCIONAL']\n",
    "columnas_a_convertir = df_impuestos.columns.drop(columnas_excluidas)\n",
    "\n",
    "# conversión solo a esas columnas\n",
    "#dado que hay valores que no son número sino guiones, \n",
    "#usaremos .apply(pd.to_numeric, errors='coerce') para reemplazar automáticamente con NaN (Not a Number) \n",
    "#esos valores con guión, permitiendo que el resto de la conversión continúe.\n",
    "\n",
    "df_impuestos[columnas_a_convertir] = df_impuestos[columnas_a_convertir].apply(pd.to_numeric, errors='coerce')\n",
    "df_impuestos[columnas_a_convertir] = df_impuestos[columnas_a_convertir] * 1000\n",
    "#convertimos los valores NaN a 0  \n",
    "df_impuestos = df_impuestos.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fe8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Diccionario ciudad -> departamento (ajustado a mayúsculas)\n",
    "ciudades_departamentos = {\n",
    "    \"ADUANAS BARRANQUILLA\": \"ATLÁNTICO\",\n",
    "    \"ADUANAS BOGOTA\": \"CUNDINAMARCA\",\n",
    "    \"ADUANAS CALI\": \"VALLE DEL CAUCA\",\n",
    "    \"ADUANAS CARTAGENA\": \"BOLÍVAR\",\n",
    "    \"ADUANAS DE CUCUTA\": \"NORTE DE SANTANDER\",\n",
    "    \"ADUANAS DE MEDELLIN\": \"ANTIOQUIA\",\n",
    "    \"IMPUESTOS BOGOTA\": \"CUNDINAMARCA\",\n",
    "    \"GRANDES CONTRIBUYENTES BOGOTA\": \"BOGOTÁ, D.C.\",\n",
    "    \"OPERERATIVA DE GRANDES CONTRIBUYENTES\": \"BOGOTÁ, D.C.\",\n",
    "    \"OPERATIVA GRANDES CONTRIBUYENTES\": \"BOGOTÁ, D.C.\",\n",
    "\n",
    "    \"ARAUCA\": \"ARAUCA\",\n",
    "    \"ARMENIA\": \"QUINDÍO\",\n",
    "    \"BARRANCABERMEJA\": \"SANTANDER\",\n",
    "    \"BARRANQUILLA\": \"ATLÁNTICO\",\n",
    "    \"BUCARAMANGA\": \"SANTANDER\",\n",
    "    \"BUENAVENTURA\": \"VALLE DEL CAUCA\",\n",
    "    \"CALI\": \"VALLE DEL CAUCA\",\n",
    "    \"CARTAGENA\": \"BOLÍVAR\",\n",
    "    \"CUCUTA\": \"NORTE DE SANTANDER\",\n",
    "    \"FLORENCIA\": \"CAQUETÁ\",\n",
    "    \"GIRARDOT\": \"CUNDINAMARCA\",\n",
    "    \"IBAGUE\": \"TOLIMA\",\n",
    "    \"INIRIDA\": \"GUAINÍA\",\n",
    "    \"IPIALES\": \"NARIÑO\",\n",
    "    \"LETICIA\": \"AMAZONAS\",\n",
    "    \"MAICAO\": \"LA GUAJIRA\",\n",
    "    \"MANIZALES\": \"CALDAS\",\n",
    "    \"MEDELLIN\": \"ANTIOQUIA\",\n",
    "    \"MITU\": \"VAUPÉS\",\n",
    "    \"MONTERIA\": \"CÓRDOBA\",\n",
    "    \"NEIVA\": \"HUILA\",\n",
    "    \"PALMIRA\": \"VALLE DEL CAUCA\",\n",
    "    \"PASTO\": \"NARIÑO\",\n",
    "    \"PEREIRA\": \"RISARALDA\",\n",
    "    \"POPAYAN\": \"CAUCA\",\n",
    "    \"PUERTO ASIS\": \"PUTUMAYO\",\n",
    "    \"PUERTO CARREÑO\": \"VICHADA\",\n",
    "    \"QUIBDO\": \"CHOCÓ\",\n",
    "    \"RIOHACHA\": \"LA GUAJIRA\",\n",
    "    \"SAN ANDRES\": \"ARCHIPIÉLAGO DE SAN ANDRÉS, PROVIDENCIA Y SANTA CATALINA\",\n",
    "    \"SAN JOSE DEL GUAVIARE\": \"GUAVIARE\",\n",
    "    \"SANTA MARTA\": \"MAGDALENA\",\n",
    "    \"SINCELEJO\": \"SUCRE\",\n",
    "    \"SOGAMOSO\": \"BOYACÁ\",\n",
    "    \"TULUA\": \"VALLE DEL CAUCA\",\n",
    "    \"TUNJA\": \"BOYACÁ\",\n",
    "    \"URABA\": \"ANTIOQUIA\",\n",
    "    \"VALLEDUPAR\": \"CESAR\",\n",
    "    \"VILLAVICENCIO\": \"META\",\n",
    "    \"YOPAL\": \"CASANARE\"\n",
    "}\n",
    "\n",
    "# Diccionario departamento -> código\n",
    "departamento_codigos = {\n",
    "    \"ANTIOQUIA\": 5,\n",
    "    \"ATLÁNTICO\": 8,\n",
    "    \"BOGOTÁ, D.C.\": 11,\n",
    "    \"BOLÍVAR\": 13,\n",
    "    \"BOYACÁ\": 15,\n",
    "    \"CALDAS\": 17,\n",
    "    \"CAQUETÁ\": 18,\n",
    "    \"CAUCA\": 19,\n",
    "    \"CESAR\": 20,\n",
    "    \"CÓRDOBA\": 23,\n",
    "    \"CUNDINAMARCA\": 25,\n",
    "    \"CHOCÓ\": 27,\n",
    "    \"HUILA\": 41,\n",
    "    \"LA GUAJIRA\": 44,\n",
    "    \"MAGDALENA\": 47,\n",
    "    \"META\": 50,\n",
    "    \"NARIÑO\": 52,\n",
    "    \"NORTE DE SANTANDER\": 54,\n",
    "    \"QUINDÍO\": 63,\n",
    "    \"RISARALDA\": 66,\n",
    "    \"SANTANDER\": 68,\n",
    "    \"SUCRE\": 70,\n",
    "    \"TOLIMA\": 73,\n",
    "    \"VALLE DEL CAUCA\": 76,\n",
    "    \"ARAUCA\": 81,\n",
    "    \"CASANARE\": 85,\n",
    "    \"PUTUMAYO\": 86,\n",
    "    \"ARCHIPIÉLAGO DE SAN ANDRÉS, PROVIDENCIA Y SANTA CATALINA\": 88,\n",
    "    \"AMAZONAS\": 91,\n",
    "    \"GUAINÍA\": 94,\n",
    "    \"GUAVIARE\": 95,\n",
    "    \"VAUPÉS\": 97,\n",
    "    \"VICHADA\": 99\n",
    "}\n",
    "\n",
    "#eliminación de filas los totales por año para poder unir las bases y generar columna dpto.\n",
    "df_impuestos_arreglado = df_impuestos[~df_impuestos[\"DIRECCIÓN SECCIONAL\"].str.contains(\"TOTAL AÑO\", case=False, na=False)].copy()\n",
    "# Asignación de departamento\n",
    "df_impuestos_arreglado[\"departamento\"] = df_impuestos_arreglado[\"DIRECCIÓN SECCIONAL\"].map(ciudades_departamentos)\n",
    "\n",
    "# 4. Asignación de  código de departamento\n",
    "df_impuestos_arreglado[\"dpto\"] = df_impuestos_arreglado[\"departamento\"].map(departamento_codigos)\n",
    "df_impuestos_arreglado['dpto'] = df_impuestos_arreglado['dpto'].apply(pd.to_numeric, errors='coerce')\n",
    "df_impuestos_arreglado = df_impuestos_arreglado.dropna(subset=[\"dpto\"])\n",
    "df_impuestos_arreglado[\"dpto\"] = df_impuestos_arreglado[\"dpto\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9051daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impuestos_arreglado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f07c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impuestos_arreglado.info(   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b3e1f",
   "metadata": {},
   "source": [
    "## Importación de dataset del DANE: Encuesta Anual Manufacturera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32268344",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "#indicación de la ruta de los datasets y el separador de los archivos csv\n",
    "ruta_datasets = r'C:\\Users\\Kayak\\OneDrive\\Escritorio\\U\\2025-2\\IA_aplicada\\proyecto\\datasets'\n",
    "CSV_SEPARATOR = ';' \n",
    "\n",
    "# Diccionario de configuración de archivos y formato exacto por año\n",
    "archivos = {\n",
    "    2018: {'nombre': 'EAM_ANONIMIZADA_2018.csv', 'formato': 'csv'},\n",
    "    2019: {'nombre': 'EAM_ANONIMIZADA_2019.csv', 'formato': 'csv'},\n",
    "    2020: {'nombre': 'EAM_ANONIMIZADA_2020.xlsx', 'formato': 'xlsx'}, \n",
    "    2021: {'nombre': 'EAM_ANONIMIZADA_2021.xlsx', 'formato': 'xlsx'}, \n",
    "    2022: {'nombre': 'EAM_ANONIMIZADA_2022.xlsx', 'formato': 'xlsx'},\n",
    "    2023: {'nombre': 'EAM_ANONIMIZADA_2023.xlsx', 'formato': 'xlsx'}\n",
    "}\n",
    "\n",
    "# Diccionario de decodificación y selección de columnas\n",
    "columnas_renombre = {\n",
    "    'dpto': 'DEPARTAMENTO',\n",
    "    'periodo': 'AÑO',\n",
    "    'C3R20C3': 'Impuesto de Renta para la Equidad',\n",
    "    'c3r25c3': 'Impuesto del 4 x 1 000',\n",
    "    'c3r37c3': 'Impuesto de Industria y Comercio',\n",
    "    'c3r38c3': 'Impuesto Predial y sobre Vehículos'\n",
    "}\n",
    "columnas_seleccion = list(columnas_renombre.keys()) # Las columnas originales que buscamos\n",
    "columnas_impuestos = list(columnas_renombre.values())[2:] # Solo los nombres de los impuestos finales\n",
    "\n",
    "# Lista para almacenar los DataFrames procesados anualmente\n",
    "list_df_anuales = []\n",
    "\n",
    "# --- 2. Bucle de Procesamiento ---\n",
    "for año, dataset in archivos.items():\n",
    "    nombre_archivo = dataset['nombre']\n",
    "    formato_archivo = dataset['formato']\n",
    "    ruta_archivo = os.path.join(ruta_datasets, nombre_archivo)\n",
    "    df_EAM = None\n",
    "\n",
    "    # A. Importación Condicional\n",
    "    try:\n",
    "        if formato_archivo == 'xlsx':\n",
    "            df_EAM = pd.read_excel(ruta_archivo) \n",
    "        elif formato_archivo == 'csv':\n",
    "            df_EAM = pd.read_csv(ruta_archivo, sep=CSV_SEPARATOR)\n",
    "        else:\n",
    "            print(f\" Error: Formato '{formato_archivo}' no reconocido.\")\n",
    "            continue\n",
    "        \n",
    "        # Estandarización de nombres: convierte los nombres de columnas a minúsculas\n",
    "        # Esto soluciona la mayoría de los KeyErrors si el archivo no respeta mayúsculas/minúsculas.\n",
    "        df_EAM.columns = df_EAM.columns.str.lower().str.strip()\n",
    "        print(f\"✅ Importado y nombres estandarizados: {nombre_archivo}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\" Error: Archivo NO encontrado en la ruta para el año {año}.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\" Error al leer el archivo {nombre_archivo}. Detalles: {e}\")\n",
    "        continue\n",
    "\n",
    "    # B. Selección y Renombramiento (Idéntico a tu referencia, pero con nombres limpios)\n",
    "    # 1. Aseguramos que la selección se haga con los nombres limpios (minúsculas)\n",
    "    columnas_a_seleccionar_limpias = [col.lower() for col in columnas_seleccion]\n",
    "    \n",
    "    try:\n",
    "        # Aquí se aplica la selección de columnas.\n",
    "        df_EAM_util = df_EAM[columnas_a_seleccionar_limpias].copy()\n",
    "    except KeyError as e:\n",
    "        print(f\" ERROR CRÍTICO en el año {año}: Columnas no encontradas. Faltan: {e}. Revisar el archivo.\")\n",
    "        print(f\"Columnas disponibles: {df_EAM.columns.tolist()}\")\n",
    "        continue\n",
    "\n",
    "    # 2. Renombramos usando los nombres limpios como clave\n",
    "    columnas_renombre_limpio = {k.lower(): v for k, v in columnas_renombre.items()}\n",
    "    df_EAM_util = df_EAM_util.rename(columns=columnas_renombre_limpio)\n",
    "    \n",
    "\n",
    "    # C. Conversión de Tipos de Datos (Necesario para sumar después de leer CSV/TXT)\n",
    "    for col in columnas_impuestos:\n",
    "        df_EAM_util[col] = pd.to_numeric(df_EAM_util[col], errors='coerce')\n",
    "\n",
    "    # D. Agrupación y Suma por Departamento (Igual que en tu referencia)\n",
    "    df_EAM_sumado_por_dpto = df_EAM_util.groupby('DEPARTAMENTO').sum(numeric_only=True).reset_index()\n",
    "\n",
    "    # E. Corrección del Campo 'AÑO'\n",
    "    df_EAM_sumado_por_dpto['AÑO'] = año\n",
    "\n",
    "    # F. Almacenamiento para concatenación\n",
    "    list_df_anuales.append(df_EAM_sumado_por_dpto)\n",
    "\n",
    "\n",
    "# --- 3. Consolidación Final ---\n",
    "# ¡Concatenación vertical (apilamiento) de todos los resúmenes anuales!\n",
    "df_EAM_consolidado = pd.concat(list_df_anuales, ignore_index=True)\n",
    "\n",
    "print(\"\\n--- PROCESO TERMINADO ---\")\n",
    "print(f\"DataFrames consolidados para los años: {min(archivos.keys())} a {max(archivos.keys())}\")\n",
    "print(f\"Total de registros consolidados (Filas): {len(df_EAM_consolidado)}\")\n",
    "print(\"\\nPrimeras filas del DataFrame Consolidado:\")\n",
    "print(df_EAM_consolidado.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92d8fc",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_EAM_consolidado.rename(columns={'DEPARTAMENTO': 'dpto'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83720ea",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_EAM_consolidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575ca8b",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_EAM_consolidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfca2f8",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_EAM_impuestos = pd.merge(df_EAM_consolidado, df_impuestos_arreglado, on='dpto', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18a6ad",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_EAM_impuestos.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
